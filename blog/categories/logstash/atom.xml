<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: logstash | blog dot lusis]]></title>
  <link href="http://lusis.github.com/blog/categories/logstash/atom.xml" rel="self"/>
  <link href="http://lusis.github.com/"/>
  <updated>2012-02-01T07:36:29-05:00</updated>
  <id>http://lusis.github.com/</id>
  <author>
    <name><![CDATA[John E. Vincent]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Load balancing Logstash with Redis]]></title>
    <link href="http://lusis.github.com/blog/2012/01/31/load-balancing-logstash-with-redis/"/>
    <updated>2012-01-31T23:24:00-05:00</updated>
    <id>http://lusis.github.com/blog/2012/01/31/load-balancing-logstash-with-redis</id>
    <content type="html"><![CDATA[<p>After yesterday's post about load balancing logstash with AMQP and RabbitMQ, I got to thinking that it might be useful to show a smilar pattern with other inputs and outputs.
To me this, is the crux of what makes Logstash so awesome. Someone asked me to describe Logstash in one sentence. The best I could come up with was:</p>

<p><blockquote><p>Logstash is a unix pipe on steroids</p></blockquote></p>

<p>I hope this post helps you understand what I meant by that</p>

<!-- more -->


<h1>Revisiting our requirements and pattern</h1>

<p>If you recall from the post <a href="http://goo.gl/vWyCH">yesterday</a>, we had the following 'requirements':</p>

<ul>
<li>No lost messages in transit/due to inputs or outputs.</li>
<li>Shipper only configuration on the source</li>
<li>Worker based filtering model</li>
<li>No duplicate messages due to transit mediums (i.e. fanout is inappropriate as all indexers would see the same message)</li>
</ul>


<h2>EDIT</h2>

<p>Originally our list stated the requirements as <em>No lost messages</em> and <em>No duplicate messages</em>. I've amended those with a slight modification to closer reflect the original intent. Please see <a href="http://blog.lusis.org/blog/2012/01/31/load-balancing-logstash-with-amqp/#comment-426175086">comment from Jelle Smet here</a> for details. Thanks Jelle!</p>

<p>Our design looked something like this:</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/gliffy-overview.png"><img src="/images/posts/load-balancing-logstash-with-amqp/gliffy-overview.png" alt="gliffy-overview.png" /></a></p>

<p>One of the reasons that post was so long was that AMQP is a complicated beast. There was quite a bit of dense frontloading I had to do to cover AMQP before we got to the meat.
We're going to take that same example, and swap out RabbitMQ for something a bit simpler and achieve the same results.</p>

<h1>Quick background on Redis</h1>

<p><a href="http://redis.io">Redis</a> is commonly lumped in with a group of data storage technologies called NoSQL. Its name is short for "REmoteDIctionaryServer". It typically falls into the "key/value" family of NoSQL.
Several things set Redis apart from most key/value systems however:</p>

<ul>
<li>"data types" as values</li>
<li>native operations on those data types</li>
<li>atomic operations</li>
<li>built-in PUB/SUB subsystem</li>
<li>No external dependencies</li>
</ul>


<h2>Data types</h2>

<p>I'm not going to go into too much detail about the data types except to list them and highlight the one we'll be leveraging. You can read more about them <a href="http://redis.io/topics/data-types">here</a></p>

<ul>
<li>Strings</li>
<li>Lists*</li>
<li>Sets</li>
<li>Hashes</li>
<li>Sorted Sets</li>
</ul>


<h3>How Logstash uses Redis</h3>

<p>Looking back at our AMQP example, we note three distinct exchange types. These are mapped to the following functionality in Redis (and Logstash <code>data_type</code> config for reference):</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/mapping-table.png"><img src="/images/posts/load-balancing-logstash-with-redis/mapping-table.png" alt="mapping-table.png" /></a></p>

<p>This is a somewhat over simplified list. In the case of a message producer, mimicing <code>direct</code> exchanges is done by writing to a Redis <code>list</code> while consumption of that is done via the Redis command <code>BLPOP</code><a href="http://redis.io/commands/blpop">*</a>. However mimicing the <code>fanout</code> and <code>topic</code> functionality is done strictly with the commands <code>PUBLISH</code><a href="http://redis.io/commands/publish">*</a>, <code>SUBSCRIBE</code><a href="http://redis.io/commands/subscribe">*</a> and <code>PSUBSCRIBE</code><a href="http://redis.io/commands/psubscribe">*</a>. It's worth reading each of those for a better understanding.</p>

<p>Oddly enough, the use of Redis as a messaging bus is something of a side effect. Redis supported lists that are auto-sorted by insert order. The <code>POP</code> command variants allowed single transaction get and remove of the data. It just fit the use case.</p>

<h1>The configs</h1>

<p>As with our previous example, we're going to show the configs needed on each side and explain them a little bit.</p>

<h2>Client-side/Producer</h2>

<p><code>
input { stdin { type =&gt; "producer"} }
output {
redis {
 host =&gt; 'localhost'
 data_type =&gt; 'list'
 key =&gt; 'logstash:redis'
}
}
</code></p>

<h3>data_type</h3>

<p>This is where we tell Logstash how to send the data to Redis. In the case, again, we're storing it in a list data type.</p>

<h3>key</h3>

<p>Unfortunately, key means different things (though with the same effect) depending on the <code>data_type</code> being used. In the case of a <code>list</code> this maps cleanly to the understanding of a <code>key</code> in a key/value system. It's common in Redis to namespace keys with a <code>:</code> though it's entirely unneccesary.</p>

<p>As an aside, when using <code>key</code> on <code>channel</code> data type, this behaves like the routing key in AMQP parlance with the exception of being able to use any separator you like (in other words, you can namespace with <code>.</code>,<code>:</code>,<code>::</code> whatever).</p>

<h2>Indexer-side/Consumer</h2>

<p><code>
input {
redis {
  host =&gt; 'localhost'
  data_type =&gt; 'list'
  key =&gt; 'logstash:redis'
  type =&gt; 'redis-input'
}
}
output {stdout {debug =&gt; true} }
</code></p>

<h3>data_type</h3>

<p>This needs to match up with the value from the output plugin. Again, in this example <code>list</code>.</p>

<h3>key</h3>

<p>In the case of a <code>list</code> this needs to map EXACTLY to the output plugin. Following on to our previous aside, for <code>data_type</code> values of <code>channel</code> input, the key must match exactly while <code>pattern_channel</code> can support wildcards. Redis PSUBSCRIBE wildcards actually much simpler than AMQP ones. You can use <code>*</code> at any point in the key name.</p>

<h1>Starting it all up</h1>

<p>We're going to simplify our original tests a little bit in the interest of brevity. Showing 2 producers and 2 consumers gives us the same benefit as showing four of each. Since we don't have the benefit of a pretty management interface, we're going to use the redis server debug information and the <code>redis-cli</code> application to allow us to see certain management information.</p>

<h2>redis-server</h2>

<p>Start the server with the command <code>redis-server</code> I'm running this from homebrew but you literally build Redis on any machine that has <code>make</code> and a compiler. That's all you need. You can even run it straight from the source directory:</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/redis-server.png"><img src="/images/posts/load-balancing-logstash-with-redis/redis-server.png" alt="redis-server.png" /></a></p>

<p>You'll notice that the redis server is periodically dumping some stats - number of connected clients and the amount of memory in use.</p>

<h2>Starting the logstash agents</h2>

<p>We're going to start two producers (redis output) and two consumers (redis input):</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/agents.png"><img src="/images/posts/load-balancing-logstash-with-redis/agents.png" alt="agents.png" /></a></p>

<p>Back in our redis-server window, you should now see two connected clients in the periodic status messages. Why not four? Because the producers don't have a persistent connection to Redis. Only the consumers do (via BLPOP):</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/two-clients.png"><img src="/images/posts/load-balancing-logstash-with-redis/two-clients.png" alt="two-clients.png" /></a></p>

<h1>Testing message flow</h1>

<p>As with our previous post, we're going to alternate messages between the two producers. In the first producer, we'll type <code>window 1</code> and in the second <code>window 2</code>. You'll see the consumers pick up the messages:</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/delivery.png"><img src="/images/posts/load-balancing-logstash-with-redis/delivery.png" alt="delivery.png" /></a></p>

<p>If you look over in the redis-server window, you'll also see that our client count went up to four. If we were to leave these clients alone, eventually it would drop back down to two.</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/new-connections.png"><img src="/images/posts/load-balancing-logstash-with-redis/new-connections.png" alt="new-connections.png" /></a></p>

<p>Feel free to run the tests a few times and get a feel for message flow.</p>

<h2>Offline consumers</h2>

<p>This is all well and good but as with the previous example, we want to test how this configuration handles the case of consumers going offline. Shut down the two indexer configs and let's verify. To do this, we're going to also open up a new window and run the <code>redis-cli</code> app. Technically, you don't even need that. You can telnet to the redis port and just run these commands yourself. We're going to use the <code>LLEN</code> command to get the size of our "backlog".</p>

<p>In the producer windows, type a few messages. Alternate between producers for maximum effect. Then go over to the <code>redis-cli</code> window and type <code>LLEN logstash:redis</code>. You should see something like the following (obviously varied by how many messages you sent):</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/llen.png"><img src="/images/posts/load-balancing-logstash-with-redis/llen.png" alt="llen.png" /></a></p>

<p>You'll also notice in the redis server window that the amount of memory in use went up slightly.</p>

<p>Now let's start our consumers back up and ensure they drain (and in insert order):</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/drain.png"><img src="/images/posts/load-balancing-logstash-with-redis/drain.png" alt="drain.png" /></a></p>

<p>Looks good to me!</p>

<h1>Persistence</h1>

<p>You might have noticed I didn't address disk-based persistence at all. This was intentional. Redis is primarily a memory-based store. However it does have support for a few different ways of persisting to disk - RDB and AOF. I'm not going to go into too much detail on those. The Redis documentation does a good job of explaining the pros and cons of each. You can read that <a href="http://redis.io/topics/persistence">here</a>.</p>

<h1>Wrap up</h1>

<p>One thing that's important to note is that Redis is pretty damn fast. The limitation for Redis is essentially memory. However if speed isn't your primary concern, there's an interesting alpha project called <a href="http://inaka.github.com/edis">edis</a> worth investigating. It is a port of Redis to Erlang. Its primary goal is better persistence for Redis. For this post I also tested Logstash against edis and I'm happy to say it works:</p>

<p><a href="/images/posts/load-balancing-logstash-with-redis/edis.png"><img src="/images/posts/load-balancing-logstash-with-redis/edis.png" alt="edis.png" /></a></p>

<p>I hope to do further testing with it in the future in a multinode setup.</p>

<h2>Part three</h2>

<p>I'm also working on a part three in this "series". The last configuration I'd like to show is doing this same setup but using <a href="http://zeromq.org">0mq</a> as the bus. This is going to be especially challenging since our 0mq support is curretly 'alpha'-ish quality. Beyond that, I plan on doing a similar series using pub/sub patterns. If you're enjoying these posts, please comment and let me know!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Load balancing Logstash with AMQP]]></title>
    <link href="http://lusis.github.com/blog/2012/01/31/load-balancing-logstash-with-amqp/"/>
    <updated>2012-01-31T01:12:00-05:00</updated>
    <id>http://lusis.github.com/blog/2012/01/31/load-balancing-logstash-with-amqp</id>
    <content type="html"><![CDATA[<p>AMQP in Logstash is one of the most complicated parts of the workflow. I've taken it on myself, as the person with the most AMQP experience (both RabbitMQ and Qpid) to try and explain as much as need for logstash users.</p>

<p><a href="https://twitter.com/patrickdebois">Patrick DeBois</a> hit me up with a common logstash design pattern that I felt warranted a full detailed post.</p>

<p><em>Warning: This is an image heavy post. Terminal screenshots are linked to larger versions</em></p>

<h2>Requirements</h2>

<ul>
<li>No lost messages in transit/due to inputs or outputs.</li>
<li>Shipper-only configuration on the source</li>
<li>Worker-based filtering model</li>
<li>No duplicate messages due to transit mediums (i.e. fanout is inappropriate as all indexers would see the same message)</li>
<li>External ElasticSearch cluster as final destination</li>
</ul>


<!-- more -->


<h2>EDIT</h2>

<p>Originally our list stated the requirements as <em>No lost messages</em> and <em>No duplicate messages</em>. I've amended those with a slight modification to closer reflect the original intent. Please see <a href="http://blog.lusis.org/blog/2012/01/31/load-balancing-logstash-with-amqp/#comment-426175086">comment from Jelle Smet here</a> for details. Thanks Jelle!</p>

<h2>Notes</h2>

<p>We're going to leave the details of filtering and client-side input up to the imagination.
For this use case we'll simply use <code>stdin</code> as our starting point. You can modify this as you see fit.
The same goes for filtering. The assumption is that your filters will be correct and not be the source of any messages NOT making it into ElasticSearch.</p>

<p>Each configuration will be explained so don't stress over it at first glance. We're also going to explicitly set some options for the sake of easier comprehension.</p>

<h1>Client-side agent config</h1>

<p>```
{
  input {</p>

<pre><code>stdin { debug =&gt; true type =&gt; "host-agent-input" }
</code></pre>

<p>  }
  output {</p>

<pre><code>amqp {
  name =&gt; "logstash-exchange"
  exchange_type =&gt; "direct"
  host =&gt; "rabbitmq-server"
  key =&gt; "logstash-routing-key"
  durable =&gt; true
  persistent =&gt; true
}
</code></pre>

<p>  }
}
```</p>

<h2>Config Explained</h2>

<p>The amqp output:</p>

<h3>name</h3>

<p>This is the name that will be provided to RabbitMQ for the exchange. By default, the Bunny driver will auto-generate a name. This won't work in this usecase because the consumers will need a known name. Remember exchanges are for producers. Queues are for consumers. When we wire up the indexer side, we'll need to know the name of the exchange to perform the binding.</p>

<h3>exchange_type</h3>

<p>For this particular design, we want to use a direct exchange. It's the only way we can guarantee that only one copy of a log message will be processed.</p>

<h3>key</h3>

<p>We're going to explicitly set the routing key as direct exchanges do not support wildcard routing key bindings. Again, we'll need this on the consumer side to ensure we get the right messages.</p>

<h3>durable</h3>

<p>This setting controls if the exchange should survive RabbitMQ restarts or not.</p>

<h3>persistent</h3>

<p>This is for the messages. Should they be persisted to disk or not?</p>

<p>Note that for a fully "no lost messages scenario" to work in RabbitMQ, you have to jump through some hoops. This is explain more below.</p>

<h2>Running the agent</h2>

<p>This same configuration should be used on ALL host agents where logs are being read. You can have variation in the inputs. You can have additional outputs however the amqp output stanza above will ensure that all messages will be sent to RabbitMQ.</p>

<h1>Indexer agent config</h1>

<p>```
input {
  amqp {</p>

<pre><code>host =&gt; "rabbitmq-server"
name =&gt; "indexer-queue"
exchange =&gt; "logstash-exchange"
key =&gt; "logstash-routing-key"
exclusive =&gt; false
durable =&gt; true
auto_delete =&gt; false
type =&gt; "logstash-indexer-input"
</code></pre>

<p>  }
}</p>

<p>filter {
  # your filters here
}</p>

<p>output {
  elasticsearch {</p>

<pre><code># your elasticsearch settings here
</code></pre>

<p>  }
}
```</p>

<h2>Config explained</h2>

<p>The amqp input:</p>

<h3>name</h3>

<p>This is the name that will be provided to RabbitMQ for the queue. Again, as with exchange, we need a known name. The reason for this is that all of our indexers are going to share a common queue. This will make sense in a moment.</p>

<h3>exchange</h3>

<p>This should match exactly with the name of the exchange that was created before in the host-side config.</p>

<h3>key</h3>

<p>This should, again, match the routing key provided in the host-side configuration exactly. <code>direct</code> exchanges do NOT support wildcard routing keys. By providing a routing key, you are creating a <code>binding</code> in RabbitMQ terms. This <code>binding</code> says "I want all messages sent to the <code>logstash-exchange</code> with a routing key of <code>logstash-routing-key</code> to be sent to the queue named <code>indexer-queue</code>.</p>

<h3>exclusive</h3>

<p>As with the exchange in the host-side config, we're going to have multiple workers using this queue. This is another AMQP detail. When you bind a queue to an exchange, a <code>channel</code> is created for the messages to flow across. A single queue can have multiple channels. This is how our worker pool is going to operate.</p>

<p><strong>You do not want a different queue name for each worker despite how weird that sounds</strong></p>

<p>If you give each worker its own queue, then you <strong>WILL</strong> get duplicate messages. It's counterintuitive, I know. Just trust me. The way to ensure that multiple consumers don't see the same message is to use mutliple channels on the same queue.</p>

<h3>durable</h3>

<p>Same as the exchange declarition, this ensures that the queue will stick around if the broker (the RabbitMQ server) restarts.</p>

<h3>auto_delete</h3>

<p>This is the setting most people miss when trying to ensure no lost messages. By default, RabbitMQ will throw away even durable queues once the last user of the queue disconnects.</p>

<h3>type</h3>

<p>This is the standard logstash requirement for inputs. They must have a <code>type</code> defined. Arbitrary string.</p>

<h1>Sidebar on RabbitMQ message reliability</h1>

<p>Simply put, RabbitMQ makes you jump through hoops to ensure that no message is lost. There's a trifecta of settings that you have to have for it to work:</p>

<ul>
<li>Your exchange must be durable with persistent messages</li>
<li>Your queue must be durable</li>
<li>Auto-delete must not be disabled</li>
</ul>


<p><strong>EVEN IF YOU DO ALL THESE THINGS, YOU CAN STILL LOSE MESSAGES!</strong></p>

<h2>Order matters</h2>

<p>I know ... you're thinking "What the F---?". There is still a scenario where you can lose messages. It has to do with how you start things up.</p>

<ul>
<li>If you start the exchange side but never start the queue side, messages are dropped on the floor</li>
<li>You can't start the queue side without first starting the exchange side</li>
</ul>


<p>While RabbitMQ let's you predeclare exchanges and queues from the command-line, it normally only creates things when someone asks for it. Since exchanges know nothing about the consumption side of the messages (the queues), creating an exchange with all the right settings does NOT create the queue and thus no binding is ever created.</p>

<p>Conversely, you can't declare a totally durable queue when there is no exchange in place to bind against.</p>

<p>Follow these rules and you'll be okay. You only need to do it once:</p>

<ul>
<li>Start a producer (the host-side logstash agent)</li>
<li>Ensure via <code>rabbitmqctl</code> or the management web interface that the exchange exists</li>
<li>Start one of the consumers (the indexer config)</li>
</ul>


<p>Once the indexer agent has started, you will be good to go. You can shutdown the indexers and messages will start piling up. You can shut everything down - rabbitmq (with backlogged messages), the indexer agent and the host-side agent. When you start RabbitMQ, the queues, exchanges and messages will all still be there. If you start an indexer agent, it will drain the outstanding messages.</p>

<p>However, if you screw the configuration up you'll have to delete the exchange and the queue via <code>rabbitmqctl</code> or the management web interface and start over.</p>

<h1>How it looks visually</h1>

<p>There are two plugins you should install with RabbitMQ:</p>

<ul>
<li>rabbitmq_management</li>
<li>rabbitmq_management_visualizer</li>
</ul>


<p>The first will provide a web interface (and HTTP API!) listening on port 55672 of your RabbitMQ server. It provides a really easy way to see messages backlogged, declared exchanges/queue and pretty much everything else. Seeing as it also provides a very nice REST api to everything inside the RabbitMQ server, you'll want it anyway if for nothing but monitoring hooks.</p>

<p>The visualizer is an ad-hoc addon that helps you see the flows through the system. It's not as pretty as the management web interface proper but it gets the job done.</p>

<h1>Starting it all up</h1>

<p>Now we can start things up</p>

<h2>Producers</h2>

<p>We're going to start up our four client side agents. These will create the exchange (or alternately connect to the existing one). If you look at the management interface, you'll see four channels established:</p>

<p>Management view:
<img src="/images/posts/load-balancing-logstash-with-amqp/amqp-four-channels.png" alt="amqp-four-channels.png" /></p>

<p>Visualizer view:
<img src="/images/posts/load-balancing-logstash-with-amqp/amqp-four-producers.png" alt="amqp-four-producers.png" /></p>

<p>Remember that until we connect with a consumer configuration (the indexer) messages sent to these exchanges WILL be lost.</p>

<h2>Consumers</h2>

<p>Now we start our indexer configurations - all four of them</p>

<p>Now if we take a peek around the management interface and the visualizer, we start to see some cool stuff.</p>

<p>In the managment interface, you'll see eight total channels - four for the queue and four for the exchange</p>

<p><img src="/images/posts/load-balancing-logstash-with-amqp/amqp-eight-channels.png" alt="amqp-eight-channels.png" /></p>

<p>If you click on "Queues" at the top and then on the entry for our <code>indexer-queue</code>, you'll see more details:</p>

<p><img src="/images/posts/load-balancing-logstash-with-amqp/amqp-indexer-queue-details.png" alt="amqp-indexer-queue-details.png" /></p>

<p>But the real visual is in the visualizer tab. Click on it and then click on the <code>indexer-queue</code> on the far right</p>

<p><img src="/images/posts/load-balancing-logstash-with-amqp/amqp-visualizer-detail.png" alt="amqp-visualizer-detail.png" /></p>

<p>You can see the lines showing the flow of messages.</p>

<p>One thing to make note of about RabbitMQ load balancing. Messages are load balanced across CONSUMERS not QUEUES. There's a subtle distinction there from RabbitMQ's semantic point of view.</p>

<h2>Testing the message flow</h2>

<p>Over in your terminal window, let's send some test messages. For this test, again, I'm using <code>stdin</code> for my origination and <code>stdout</code> to mimic the ElasticSearch destination.</p>

<p>In my first input window, I'm going just type 1 through 4 with a newline after each. This should result in each consumer getting a message round-robin style:</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/load-balance-test-1.png"><img src="/images/posts/load-balancing-logstash-with-amqp/load-balance-test-1.png" alt="load-balance-test-1.png" /></a></p>

<p>Now I'm going to cycle through the input windows and send a single message from each:</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/load-balance-test-4.png"><img src="/images/posts/load-balancing-logstash-with-amqp/load-balance-test-4.png" alt="load-balance-test-4.png" /></a></p>

<p>You can see that messages 4-7 were sent round-robin style.</p>

<h2>Testing persistence</h2>

<p>All of this is for naught if we lose messages because our workers are offline. Let's shutdown all of our workers and send a bunch of messages from each input window:</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/workers-offline-terminal.png"><img src="/images/posts/load-balancing-logstash-with-amqp/workers-offline-terminal.png" alt="workers-offline-terminal.png" /></a></p>

<p>We sent two lines of text per window. This amounts to eight log messages that should be queued up for us. Let's check the management interface:</p>

<p><img src="/images/posts/load-balancing-logstash-with-amqp/eight-messages-waiting.png" alt="eight-messages-waiting.png" /></p>

<p>Now if we stop rabbitmq entirely and restart it, those messages should still be there (along with the queue and exchanges we created).</p>

<p>Once you've verified that, start one of the workers back up. When it comes fully online, it should drain all of the messages from the exchange:</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/drained-messages.png"><img src="/images/posts/load-balancing-logstash-with-amqp/drained-messages.png" alt="drained-messages.png" /></a></p>

<p>Yep, there they went. The last two messages you get should be the ones from window 4. This is another basic functionality of message queue software in general. Messages should be delivered in the order in which they were recieved.</p>

<h1>One last diagram</h1>

<p>Here's a flowchart I created with Gliffy to show what the high-level overview of our setup would look like. Hope it helps and feel free to hit me up on freenode irc in the <code>#logstash</code> channel or on <a href="https://twitter.com/lusis">twitter</a>.</p>

<p><a href="/images/posts/load-balancing-logstash-with-amqp/gliffy-overview.png"><img src="/images/posts/load-balancing-logstash-with-amqp/gliffy-overview.png" alt="gliffy-overview.png" /></a></p>

<p><em>This post will eventually make its way into the <a href="http://cookbook.logstash.net">Logstash Cookbook Site</a>.</em></p>
]]></content>
  </entry>
  
</feed>
